
TODO:
	-- errors list for cross validation are not listed in other models should be done like bagging
        -- check the difference between predicting using Cross validation vs regressor itself (See Adaboost vs others
	--output training accuracy as well and plot it along w test accuracy
	--add a section using pipeline, make a function that takes model,
	rather than applying each model. instead of putting original dataset just give a



Dataset:
https://www.kaggle.com/datasets/wspirat/germany-used-cars-dataset-2023
  --Cleaned
  https://www.kaggle.com/code/scarfsman/german-used-cars-data-cleaning-eda

   --Pipelines and models via regression and KNN:
   https://www.kaggle.com/code/alexandermalkov/training-predictions
   --Pipeline, models and OPtimising:
   https://www.kaggle.com/code/alexandermalkov/transfomers-pipeline-and-gridsearch
